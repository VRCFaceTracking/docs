"use strict";(self.webpackChunkvrcft_docs=self.webpackChunkvrcft_docs||[]).push([[3252],{3905:(e,t,a)=>{a.d(t,{Zo:()=>l,kt:()=>h});var i=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,i,o=function(e,t){if(null==e)return{};var a,i,o={},n=Object.keys(e);for(i=0;i<n.length;i++)a=n[i],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(i=0;i<n.length;i++)a=n[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var c=i.createContext({}),p=function(e){var t=i.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},l=function(e){var t=p(e.components);return i.createElement(c.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var a=e.components,o=e.mdxType,n=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=p(a),m=o,h=d["".concat(c,".").concat(m)]||d[m]||u[m]||n;return a?i.createElement(h,r(r({ref:t},l),{},{components:a})):i.createElement(h,r({ref:t},l))}));function h(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var n=a.length,r=new Array(n);r[0]=m;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[d]="string"==typeof e?e:o,r[1]=s;for(var p=2;p<n;p++)r[p]=a[p];return i.createElement.apply(null,r)}return i.createElement.apply(null,a)}m.displayName="MDXCreateElement"},5340:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>n,metadata:()=>s,toc:()=>p});var i=a(87462),o=(a(67294),a(3905));const n={},r="iFacialMocap (Desktop Application)",s={unversionedId:"hardware/desktop/webcam/ifacialmocap-webcam",id:"hardware/desktop/webcam/ifacialmocap-webcam",title:"iFacialMocap (Desktop Application)",description:"iFacialMocap for Nvidia uses a Webcam with either RTX Nvidia cards or MediaPipe for Face Tracking",source:"@site/docs/hardware/desktop/webcam/ifacialmocap-webcam.mdx",sourceDirName:"hardware/desktop/webcam",slug:"/hardware/desktop/webcam/ifacialmocap-webcam",permalink:"/docs/hardware/desktop/webcam/ifacialmocap-webcam",draft:!1,editUrl:"https://github.com/VRCFaceTracking/docs/edit/master/docs/hardware/desktop/webcam/ifacialmocap-webcam.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"FoxyFace",permalink:"/docs/hardware/desktop/webcam/foxyface"},next:{title:"MediaPipe",permalink:"/docs/hardware/desktop/webcam/mediapipe"}},c={},p=[{value:"Setup",id:"setup",level:2},{value:"Setting up iFacialMocap",id:"setting-up-ifacialmocap",level:2},{value:"Camera input",id:"camera-input",level:3},{value:"Calibration",id:"calibration",level:3},{value:"Adjusting Multipliers and Smoothing",id:"adjusting-multipliers-and-smoothing",level:3}],l={toc:p},d="wrapper";function u(e){let{components:t,...n}=e;return(0,o.kt)(d,(0,i.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"ifacialmocap-desktop-application"},"iFacialMocap (Desktop Application)"),(0,o.kt)("p",null,"iFacialMocap for Nvidia uses a Webcam with either RTX Nvidia cards or MediaPipe for Face Tracking "),(0,o.kt)("p",null,"This guide will walk-through setting up the ",(0,o.kt)("em",{parentName:"p"},"iFacialMocap")," PC App from the ",(0,o.kt)("a",{parentName:"p",href:"https://apps.microsoft.com/detail/9n01fgs2zk3x?hl=en-US&gl=US"},"Microsoft Store")," and the corresponding VRCFT tracking module."),(0,o.kt)("h2",{id:"setup"},"Setup"),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"It's recommended to use the Nvidia BROADCAST Input which requieres an RTX Card (RTX 2000 or above)."),(0,o.kt)("p",{parentName:"admonition"},"You can run this without an Nvidia RTX Card by changing the Input to Mediapipe.")),(0,o.kt)("admonition",{type:"tip"},(0,o.kt)("p",{parentName:"admonition"},'The Input named "iFacialmocap" should allow you to connect either an iPhone or android running iFacialMocap / MeowFace, but you should be connecting them directly to VRCFT with their respective modules rather than directing them through this app')),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Install ",(0,o.kt)("a",{parentName:"li",href:"https://apps.microsoft.com/detail/9n01fgs2zk3x?hl=en-US&gl=US"},"iFacialMocap for Nvidia BROADCAST")," from the microsoft store"),(0,o.kt)("li",{parentName:"ol"},"If you wish to use an RTX Card, install the latest ",(0,o.kt)("a",{parentName:"li",href:"https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-sdk/resources/"},"Nvidia AR SDK")," from the webpage")),(0,o.kt)("admonition",{type:"warning"},(0,o.kt)("p",{parentName:"admonition"},"Make sure the AR SDK is downloaded for YOUR series of cards or it may not work correctly, make sure to also grab the latest version used by Vtube Studio")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},'Start VRCFaceTracking and install the "',(0,o.kt)("strong",{parentName:"li"},"iFacialMocap"),'" VRCFT module from the ',(0,o.kt)("a",{target:"_blank",href:a(34144).Z+"#module-registry"},"VRCFaceTracking Module Registry"),"."),(0,o.kt)("li",{parentName:"ol"},'Start the "',(0,o.kt)("strong",{parentName:"li"},"iFacialMocap Powered by Nvidia BROADCAST"),'" app from your taskbar'),(0,o.kt)("li",{parentName:"ol"},"Change the ",(0,o.kt)("strong",{parentName:"li"},"INPUT")," to either Nvidia Broadcast (if using an RTX Card) or Mediapipe"),(0,o.kt)("li",{parentName:"ol"},"Change the ",(0,o.kt)("strong",{parentName:"li"},"OUTPUT")," to iFacialMocap")),(0,o.kt)("h2",{id:"setting-up-ifacialmocap"},"Setting up iFacialMocap"),(0,o.kt)("h3",{id:"camera-input"},"Camera input"),(0,o.kt)("p",null,'You can click on "Open Advanced Setting" to open the settings menu, you can look for the section called "Nvidia Display" (RTX) or "Show/Hide Camera" (Mediapipe), just below these options you should see the name of your camera along with its index'),(0,o.kt)("admonition",{type:"warning"},(0,o.kt)("p",{parentName:"admonition"},"Sometimes this index can be wrong and your camera might get the name of another camera, this usually happens if you were to plug a new video device before opening the app (i.e. you connected a capture card)."),(0,o.kt)("p",{parentName:"admonition"},"If the demo avatar or camera output is not showing, make sure that:\nA. The camera is not being used by another app\nB. Try out other cameras and see if it works")),(0,o.kt)("admonition",{type:"warning"},(0,o.kt)("p",{parentName:"admonition"},"Windows 11 has a lot of issues with getting the camera output working, so far the only method to get this working again is by reinstalling Windows, but take this as a last resort thing and try the troubleshooting mentioned above, or trying out other tracking methods such as ",(0,o.kt)("a",{parentName:"p",href:"https://docs.vrcft.io/docs/hardware/desktop/webcam/foxyface"},"FoxyFace"),",")),(0,o.kt)("h3",{id:"calibration"},"Calibration"),(0,o.kt)("p",null,"You can reset your head, eye and mouth rotations by clicking the ",(0,o.kt)("strong",{parentName:"p"},"Calibration")," button, for the best calibration"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Position your camera where you want it to be (preferably above the monitor)"),(0,o.kt)("li",{parentName:"ol"},'While looking forwards towards the center of your monitor (i.e. towards your VRC desktop cursor), tap the "Calibration" button in the app'),(0,o.kt)("li",{parentName:"ol"},"If using Nvidia broadcast, you should see a demo face shifting in place and looking straight, indicating that the head orientation and face tracking has successfully been reset")),(0,o.kt)("h3",{id:"adjusting-multipliers-and-smoothing"},"Adjusting Multipliers and Smoothing"),(0,o.kt)("p",null,'You can click on "Open Advanced Setting" to open the settings menu, below the Camera settings and "Send Version" section, you should find the Smoothing options, you can increase the value of the Blendshapes to reduce jitter, increasing this too much will introduce latency, so adjust carefully'),(0,o.kt)("admonition",{type:"tip"},(0,o.kt)("p",{parentName:"admonition"},"You can also increase the blendshape ",(0,o.kt)("strong",{parentName:"p"},"Weight"),", aka how likely it is to trigger a blendshape, by going further down into the individual blednshape settings, it's recommended to ",(0,o.kt)("strong",{parentName:"p"},"ONLY")," increase the weight value, as other options are aimed towards vtubing apps and not VRCFT\n::"),(0,o.kt)("h3",{parentName:"admonition",id:"tracked-blendshapes"},"Tracked Blendshapes"),(0,o.kt)("p",{parentName:"admonition"},"Although the app lists all 52 ARKit blendshapes within its settings, it does not track the ",(0,o.kt)("strong",{parentName:"p"},"tongueOut")," and ",(0,o.kt)("strong",{parentName:"p"},"cheekPuff* blendshapes, and may have trouble with suttle blendshapes such as "),"mouthShrug**, either way it's a very stable tracking method which works universally between vtubing apps and now VRCFT"),(0,o.kt)("h2",{parentName:"admonition",id:"module"},"Module"),(0,o.kt)("p",{parentName:"admonition"},"Interested in the source code? Check out the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/Shuisho10/VRC_iFacialMocap"},"iFacialMocap module source repository"))))}u.isMDXComponent=!0},34144:(e,t,a)=>{a.d(t,{Z:()=>i});const i=a.p+"assets/files/vrcft-ef85d22aa5623f99fffc313d379658d2.mdx"}}]);