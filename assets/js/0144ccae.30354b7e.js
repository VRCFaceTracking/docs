"use strict";(self.webpackChunkvrcft_docs=self.webpackChunkvrcft_docs||[]).push([[3582],{3905:(e,t,a)=>{a.d(t,{Zo:()=>s,kt:()=>m});var o=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,o)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,o,i=function(e,t){if(null==e)return{};var a,o,i={},n=Object.keys(e);for(o=0;o<n.length;o++)a=n[o],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(o=0;o<n.length;o++)a=n[o],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=o.createContext({}),c=function(e){var t=o.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},s=function(e){var t=c(e.components);return o.createElement(l.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},h=o.forwardRef((function(e,t){var a=e.components,i=e.mdxType,n=e.originalType,l=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),u=c(a),h=i,m=u["".concat(l,".").concat(h)]||u[h]||d[h]||n;return a?o.createElement(m,r(r({ref:t},s),{},{components:a})):o.createElement(m,r({ref:t},s))}));function m(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=a.length,r=new Array(n);r[0]=h;var p={};for(var l in t)hasOwnProperty.call(t,l)&&(p[l]=t[l]);p.originalType=e,p[u]="string"==typeof e?e:i,r[1]=p;for(var c=2;c<n;c++)r[c]=a[c];return o.createElement.apply(null,r)}return o.createElement.apply(null,a)}h.displayName="MDXCreateElement"},87216:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>n,metadata:()=>p,toc:()=>c});var o=a(87462),i=(a(67294),a(3905));const n={},r="iFacialMocap (iPhone App)",p={unversionedId:"hardware/desktop/iphone/ifacialmocap-iphone",id:"hardware/desktop/iphone/ifacialmocap-iphone",title:"iFacialMocap (iPhone App)",description:"This guide will walk-through setting up the iFacialMocap iOS/iPadOS app and the corresponding VRCFT tracking module.",source:"@site/docs/hardware/desktop/iphone/ifacialmocap-iphone.mdx",sourceDirName:"hardware/desktop/iphone",slug:"/hardware/desktop/iphone/ifacialmocap-iphone",permalink:"/docs/hardware/desktop/iphone/ifacialmocap-iphone",draft:!1,editUrl:"https://github.com/VRCFaceTracking/docs/edit/master/docs/hardware/desktop/iphone/ifacialmocap-iphone.mdx",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"iPhone / iPad",permalink:"/docs/hardware/desktop/iphone/"},next:{title:"Unreal Live Link Face",permalink:"/docs/hardware/desktop/iphone/livelink"}},l={},c=[{value:"Setup",id:"setup",level:2},{value:"Using iFacialMocap / FaceMotion3D",id:"using-ifacialmocap--facemotion3d",level:2},{value:"Recentering",id:"recentering",level:3},{value:"Adjusting Weight and Smoothing",id:"adjusting-weight-and-smoothing",level:3},{value:"Module",id:"module",level:2}],s={toc:c},u="wrapper";function d(e){let{components:t,...n}=e;return(0,i.kt)(u,(0,o.Z)({},s,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"ifacialmocap-iphone-app"},"iFacialMocap (iPhone App)"),(0,i.kt)("p",null,"This guide will walk-through setting up the ",(0,i.kt)("em",{parentName:"p"},"iFacialMocap")," iOS/iPadOS app and the corresponding VRCFT tracking module."),(0,i.kt)("h2",{id:"setup"},"Setup"),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"Ensure that your Apple device is connected to the ",(0,i.kt)("strong",{parentName:"p"},"same network as your computer"),"!")),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},'The first time setting this up, your phone should ask if you want to give permission for the iFacialMocap/FaceMotion3D app to access your Local Network.\nMake sure to tap "Allow", otherwise the app will be completely blocked from sending data! ')),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Install one of the following apps on your Apple device:"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://apps.apple.com/us/app/ifacialmocap/id1489470545"},"iFacialMocap"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://apps.apple.com/us/app/ifacialmocaptr/id1520971310"},"iFacialMocapTr")," (Free trial version, only use for testing)."),(0,i.kt)("li",{parentName:"ul"},'"Newer" app ',(0,i.kt)("a",{parentName:"li",href:"https://apps.apple.com/us/app/facemotion3d/id1507538005"},"FaceMotion3D")," (Not recommended as it's more expensive with no practical benefit)."))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},'Start VRCFaceTracking and install the "',(0,i.kt)("strong",{parentName:"p"},"iFacialMocap"),'" VRCFT module from the ',(0,i.kt)("a",{target:"_blank",href:a(34144).Z+"#module-registry"},"VRCFaceTracking Module Registry"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Go to the Output tab in VRCFT and look for the message printing out your computer's ",(0,i.kt)("em",{parentName:"p"},"local IP address"),"."),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Verify that the IP address is the local IP of your computer on your local network. It should start with ",(0,i.kt)("em",{parentName:"li"},"192.168.X.X"),"."))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Open the iFacialMocap app on your Apple device, tap the gear in the top right to open settings, then tap the ",(0,i.kt)("strong",{parentName:"p"},"Destination IP address")," option under ",(0,i.kt)("em",{parentName:"p"},"Destination setting"),".\nEnter in the local IP address of your computer as found in step 3."),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'If you are using FaceMotion3D, tap the "Live" button in the top left, set the Live Stream type to "Other", and enter in the local IP address of your computer in the provided field.'))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Return to the main iFacialMocap screen. Whenever you are in this screen, the app should be streaming data."),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'If you are using FaceMotion3D, simply tap the "Connect" button.'))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Verify that the module has initialized in VRCFT."))),(0,i.kt)("h2",{id:"using-ifacialmocap--facemotion3d"},"Using iFacialMocap / FaceMotion3D"),(0,i.kt)("h3",{id:"recentering"},"Recentering"),(0,i.kt)("p",null,'You can "zero out" your head\'s position and rotation values using the "look forward" (iFacialMocap) or "Reset" (FaceMotion3D) buttons at the bottom right the main screen.\nThis is useful to help your avatar look straight forward when you look at the center of your screen, even if your phone is below, above, or to the side of your monitor. '),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Position your phone how you could like it to stay during use."),(0,i.kt)("li",{parentName:"ol"},'While looking forwards towards the center of your monitor (i.e. towards your VRC desktop cursor), tap the "look forward"/Reset button in the app'),(0,i.kt)("li",{parentName:"ol"},"You should see the rotation of the demo face snap to face directly outwards from the screen, indicating that the head orientation has successfully been reset")),(0,i.kt)("h3",{id:"adjusting-weight-and-smoothing"},"Adjusting Weight and Smoothing"),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"Most people shouldn't need to mess around with these settings, but feel free to tweak them if you think you can improve something or you'd like a blendshape to be easier to trigger.")),(0,i.kt)("p",null,'iFacialMocap and FaceMotion3D allow you to artificially adjust the tracked values for each blendshape streamed to VRCFT (or other software). Tap the "Settings" gear icon (top right in iFacialMocap, bottom left in FaceMotion3D) and look for the ',(0,i.kt)("em",{parentName:"p"},'"Adjust motion weight"')," and ",(0,i.kt)("em",{parentName:"p"},'"Smoothing motion'),'" menus.'),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Increase or decrease specific blendshape ",(0,i.kt)("strong",{parentName:"p"},"Weight")," ",(0,i.kt)("em",{parentName:"p"},"(how likely it is to trigger a blendshape)")," to make a blendshape easier or harder to trigger.")),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Increase the smoothing value to reduce jitter, but increasing this too much will introduce latency, so adjust carefully.")),(0,i.kt)("h2",{id:"module"},"Module"),(0,i.kt)("p",null,"Interested in the source code? Check out the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Shuisho10/VRC_iFacialMocap"},"iFacialMocap module source repository")))}d.isMDXComponent=!0},34144:(e,t,a)=>{a.d(t,{Z:()=>o});const o=a.p+"assets/files/vrcft-ef85d22aa5623f99fffc313d379658d2.mdx"}}]);